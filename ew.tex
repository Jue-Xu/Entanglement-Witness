\documentclass[
%reprint,
%preprint, 
% 11pt,
10pt,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
% frontmatterverbose, 
%preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
aps,
pra,
linenumbers,
% twocolumn,
% prl,
% prb,
% prd,
% rmp,
% prstab,
% prstper,
floatfix,
%longbibliography
]{revtex4-2} 
% \usepackage{revquantum}
% new linux font, ignore mono
% \usepackage[mono=false]{libertine} 
% \renewcommand{\baselinestretch}{1.05}
% \usepackage[top=0.7in,left=1in,bottom=1in,right=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,epsfig,graphicx,mathrsfs,amsfonts,dsfont,bbm}
% \usepackage{bbm} % for \mathbb{1}, but ruins the letter
% \usepackage{unicode-math}
% \DeclareMathOperator*{\argmax}{argmax}
% \DeclareMathOperator*{\argmin}{argmin}
\usepackage{pict2e}
\usepackage[percent]{overpic}
\usepackage{color}
\usepackage{listings}
\usepackage{caption}
% \usepackage{fullpage}
\usepackage[toc,title,titletoc,header]{appendix}
\usepackage{color}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage{hyperref}
\hypersetup{
    citecolor=magenta,
    colorlinks=true,
    linkcolor=blue,
    filecolor=green,      
    urlcolor=cyan,
}
\usepackage[capitalise]{cleveref}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{tkz-graph} % graph theory
%\usepackage{tikzit}
%\input{path_integral.tikzstyles}
\usepackage{braket}
\usepackage{physics}
% \usepackage{luatex85} % for qcircuit
\usepackage{luatex85,qcircuit}
\usepackage{blkarray}
\usepackage[linesnumbered,ruled,vlined,algosection]{algorithm2e}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}

% \setlength\parindent{0pt}
\setcounter{secnumdepth}{3}

\theoremstyle{plain}
\newtheorem{axiom}{Axiom}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{conjecture}{Conjecture} 
\newtheorem{question}{Question} 
\newtheorem{claim}{Claim} 
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation} 
\newtheorem{fact}{Fact}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
\newtheorem{problem}{Problem}


\input{./macros.tex}
\newcommand{\kernel}{k}
\newcommand{\ew}{\hat{W}}
\newcommand{\ghz}{\text{GHZ}}
\newcommand{\jsd}{D_\text{JS}}
\newcommand{\qjs}{\text{QJS}}
\newcommand{\kl}{D_\text{KL}}
\newcommand{\shadow}{\textup{shadow}}
\newcommand{\noise}{\text{noise}}
\newcommand{\qnn}{\textup{QNN}}
\newcommand{\ntk}{\textup{NT}}
\newcommand{\ppt}{\textup{PPT}}
\newcommand{\stbz}{\hat{S}}
\newcommand{\ob}{\hat{O}}
\newcommand{\separable}{S}

\renewcommand{\llaplacian}{\hat{\mathfrak{L}}}
%\newcommand{\zpartition}{\mathcal{Z}}
\newcommand{\hamiltonian}{\hat{H}}
\newcommand{\U}{\hat{U}}
\newcommand{\subgroup}{\mathbb{H}}
\newcommand{\ppartition}{\mathcal{P}}
\newcommand{\dm}{\rho}
\newcommand{\oracle}{\hat{O}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\proj}{\hat{P}}
%\newcommand{\deltat}{\Delta t}
%\newcommand{\deltatau}{\Delta \tau}
\newcommand{\cz}{\textup{\textsc{cz}}}
\newcommand{\cx}{\textup{\textsc{cx}}}
\newcommand{\toffoli}{\textup{\textsc{toffoli}}}
\newcommand{\lleft}{\leftarrow}
\newcommand{\rright}{\rightarrow}
\newcommand{\intinf}{\int_{-\infty}^{\infty}}

% disable subsections and subsubsections in the TOC
\makeatletter
%\def\l@subsection#1#2{}
\def\l@subsubsection#1#2{}
\makeatother

\begin{document}
%%%%%%%%%%%%%%%%%%%
\title{Towards efficient and robust (universal) detection of entanglement structure}
\author{Jue Xu}
\email{juexu@cs.umd.edu}
\author{Qi Zhao}
\email{email}
% \affiliation{Department of Computer Science, University of Maryland, College Park.}
\date{\today}
%%%%%%%%%%%%%%%%%%%
% \vspace{10mm}
\begin{abstract}
	Verification (detection) of entanglement structure is an indispensable step for practical quantum computation (communication).
	In this work, we compare complexity and performance of several recently-developed methods, including entanglement witness methods, shadow tomography, classical machine learning, and quantum algorithms (circuits).
	We illustrate the advantages and limitations of machine learning and quantum algorithms.
\end{abstract}

\maketitle
% \setcounter{tocdepth}{0}
 \tableofcontents
% \newpage

%%%%%%%%%%%%%%%Content%%%%%%%%%%%%%%%
\section{Introduction}
Entanglement \cite{horodeckiQuantumEntanglement2009} is the key ingredient of quantum computation \cite{}, quantum communication \cite{}, and quantum cryptography \cite{}.
For practical purpose, it is essential to benckmark (characterize) multipartite entanglement structures of target states.
We review the recently developed methods to entanglement detection: entanglement witness \cite{zhouDetectingMultipartiteEntanglement2019}, shadow tomography \cite{huangPredictingManyProperties2020}, classical machine learning \cite{huangPowerDataQuantum2021}, and quantum (variational/circuit) algorithms \cite{quekMultivariateTraceEstimation2022}.

\section{Preliminaries}
% \subsection{Related works}
% \subsection{Notations}


Notations: 
The hats on the matrices such as $\hat{A}$, $\hamiltonian$, $\dm$ (omitted), $\ob$, $\ew$, emphasize that they play the roles of operators (Hermitian matrices).
Denote vector (matrix) $\vbx$, $\vb{K}$ by boldface font.
A simle (undirected, unweighted) graph $\graph=(V,E)$ is described by vertices $V$ and edges $E$.

For specific purpose, we use different basis (representations) for quantum states.
One is the computational basis $\qty{\ket{z}}$ with $z\in \qty[2^n]$ where $n$ is the number of qubits,
while another useful one is the binary representation of computational basis $\qty{\ket{\vbx}\equiv\ket{x_1}\ket{x_2}\dots\ket{x_n}}$ with $x_j\in \qty{0,1}$. 
For simplicity, we let $N \equiv 2^n$ and $\ket{\vb{0}}\equiv\ket{0^n} \equiv\ket{0}^{\otimes n}$ if no ambiguity.
shorthand $\ket{\psi_A}\ket{\psi_B}\equiv \ket{\psi_A}\otimes \ket{\psi_B}$.
Hadamard basis $\ket{+}: = (\ket{0}+\ket{1})/\sqrt{2} $.

\subsection{Entanglement detection}

\subsubsection{Bipartite entanglement}
Large scale entanglement is the (main) resource of quantum advantages in quantum computation and communication.
Firstly, we consider the simplest entanglement structure: bipartite separable case.
% \begin{definition}[Entangled state]\label{def:entangled_state}
% 	Consider a $n$-partite (subsystem) system $\hilbertspace=\bigotimes_i^n \hilbertspace_i$,
% 	separable states or product states are i.e.,
% 	\begin{equation}
% 		\ket{\Psi} = \bigotimes_i \ket{\psi_i}
% 	\end{equation}
% 	entangled pure state is a quantum state that cannot be written as a (tensor) product state (inseparable). 
% 	For (generalize) mixed states, a mixed entangled state is a convex combination of entangled pure state???, that is
% 	\begin{equation}
% 		\rho = \sum_i p_i\op{\Psi_i},\forall i,p_i\ge 0, \sum_i p_i =1
% 	\end{equation}
% 	density matrix $\dm$ (trace one, Hermitian, PSD)	...
% \end{definition}
\begin{definition}[density matrix]\label{def:density_matrix}
	pure state $\ket{\psi}$;
	density matrix $\dm$ (trace one, Hermitian, PSD)	...
\end{definition}
% \begin{example}
% 	Bell states
% \end{example}
Many methods [...] have been developed to determine whether a state is separable.
\begin{definition}[bipartite separable]\label{def:bipartite_separable}
	A pure state is (bi-)separable if it is in a tensor product form $\ket{\psi_b}=\ket{\phi_A}\otimes\ket{\phi_{\bar{A}}}$, 
	where $\ppartition_2 = \qty{ A, \bar{A} }$ is a bipartition of the qubits in the system.
	Note that the state $\ket{\phi_A}$ may be entangled, thus the state $\ket{\psi}$ is not necessarily \nameref{def:fully_separable}.
	A mixed state is separable iff it can be written as a convex combination of pure biseparable states $\dm=\sum_i p_i \op{\psi_i}$ where $\ket{\psi_i}$ may be biseparable with respect to different partitions.
	The simple statement “The state is entangled” would still allow that only two of the qubits are entangled while the rest is in a product state.

	Consider a bipartite system $AB$ with the Hilbert space $\hilbertspace_A \otimes \hilbertspace_B$, where $\hilbertspace_A$ has dimension $d_A$ and $\hilbertspace_B$ has dimensional $d_B$, respectively.
	A state $\dm_{AB}$ is \emph{separable} if it can be writen as a convex combination $\dm_{AB}= \sum_i \lambda_i \dm_{A,i} \otimes \dm_{B,i}$ with a probability distribution $\lambda_i\ge 0$ and $\sum_i \lambda_i = 1$. Otherwise, $\dm_{AB}$ is entangled.

	Note that each separable state $\ket{\psi_b}$ in the summation can have different bipartitions.
	The separable state set is denoted as $S_b$.
	There is another restricted way for the extension to mixed states. 
	A state is $\ppartition_2$-separable, if it is a mixing of pure separable states with a same partition $\ppartition_2$, 
	and we denote the state set as $S_b^{\ppartition_2}$. 
	entangled state?...
\end{definition}
% It is clear that $S_b^{\ppartition_2}\subset S_b$, and $S_b$ can be generated by the convex mixture of all possible $S_b^{\ppartition_2}$.

% \subsubsection{entanglement measures}
Rather than qualitatively determining (bi)separability, there are measures to quantify entanglement
\begin{definition}[Schmidt measure]\label{def:schmidt_measure}
	Consider the following bipartite pure state, written in Schmidt form:
	\begin{equation}
		\ket{\psi} = \sum_i^r \sqrt{p_i} \ket{\phi_i^A}\otimes\ket{\phi_i^B}
		\label{eq:schmidt_decomposition}
	\end{equation}
	where $\qty{\ket{\phi_i^A}}$ is a basis for $\hilbertspace_A$ and $\qty{\ket{\phi_i^A}}$ for $\hilbertspace_B$.
	The strictly positive values $\sqrt{p_i}$ in the Schmidt decomposition are its \emph{Schmidt coefficients}. 
	The number of Schmidt coefficients, counted with multiplicity, is called its \emph{Schmidt rank}, or Schmidt number. (Schmidt rank ?? $\text{SR}^A(\psi)=\rank(\rho_{\psi}^A)$)
	Schmidt measure is minimum of $\log_2 r$ where $r$ is number of terms in an expansion of the state in product basis.
\end{definition}

% \begin{remark}
% 	When a bipartite vector is written in the Schmidt basis, it is very easy to compute the partial trace of either subsystem	
% 	\begin{equation}
% 		\Tr_B(\op{\psi}) = \sum_i p_i \op{\phi_i^A}
% 	\end{equation}
% \end{remark}
\begin{definition}[entropy]\label{def:entropy}
	In quantum mechanics (information), the von Neumann \emph{entropy} of a density matrix is $H_N(\dm): = -\Tr(\dm \log \dm)=-\sum_i\lambda_i\log(\lambda_i)$;
	In classical information (statistical) theory, the Shannon entropy of a probability distribution $P$ is  $H_S(P):= -\sum_i P(x_i) \log P(x_i)$.
	relative entropy (\nameref{def:divergence})
\end{definition}
\begin{definition}[partial trace]\label{def:partial_trace}
	% partial trace;
	reduced density matrix $\dm_A = \Tr_B(\dm_{AB})$
\end{definition}
\begin{remark}
	% (def partial trace ...)
	a pure (bipartite) state is entangled $\iff$ the reduced state $\dm^A=\Tr_A(\dm)$ is mixed.
	The mixedness of this reduced state allows one to quantify the amount of entanglement in this state.
\end{remark}
\begin{definition}[entanglement entropy]\label{def:entanglement_entropy}
	The bipartite \emph{von Neumann entanglement entropy} $S$
	is defined as the von Neumann entropy of either of
	its reduced density matrix $\dm_A$.
	For a pure state $\dm_{AB}=\op{\Psi}{\Psi}_{AB}$,
	it is given by
	\begin{equation}
		E(\Psi_{AB}) 
		= S(\dm_A)
		= -\Tr(\dm_A \log \dm_A)
		= -\Tr(\dm_B \log \dm_B)
		= S(\dm_B)
	\end{equation}
	where $\dm_A= \Tr_B(\dm_{AB})$ and $\dm_B = \Tr_A(\dm_{AB})$ 
	are the reduced density matrices for each partition.
	With Schmidt decomposition (\cref{eq:schmidt_decomposition}), the entropy of entanglement is simply $-\sum_ip_i^2\log(p_i)$.
	the $n$th Renyi entropy,
	$S_n = \frac{1}{n-1} \log (R_n)$
	% \begin{equation}
	% 	S_n = \frac{1}{n-1} \log (R_n)
	% \end{equation}
	where $R_n = \Tr(\dm^n_A)$
\end{definition}
% \begin{definition}[partial trace]
% 	partial trace
% \end{definition}
\begin{definition}[maximally entangled]
	a state vector is \emph{maximually entangled} $\iff$ the reduced state at one qubit is maximally mixed, i.e.,
	$\Tr_A(\op{\psi})=\frac{1}{2}$.
\end{definition}
Classically, the hardness of determining the bipartite separability.
\begin{theorem}[\cite{gurvitsClassicalDeterministicComplexity2003}]
	% The problem of determining whether a given quantum state is entangled lies at the heart of quantum information processing, which is an NP-hard problem in general.
	The weak membership problem for the convex set of separable normalized bipartite density matrices is \nameref{def:np}-Hard.
	\textbf{Input}: unknown state?? formal definition of the problem
	% \begin{itemize}
	% 	\item \textbf{Input}: ??
	% 	\item \textbf{Output}: ??
	% \end{itemize}
\end{theorem}
% \begin{question}
	However, we do not know 
	% specific cases? 
	approximately correct complexity? quantum complexity? machine learning (data)? for entanglement () problem? multipartite?
% \end{question}

\begin{theorem}[PPT criterion]\label{thm:ppt}
	the positive partial transpose (\ppt) criterion, saying that a separable state (\nameref{def:bipartite_separable}) must have PPT?.
	Note, it is only necessary and sufficient when $d_A d_B \le 6$.
	Another widely used one is the k-symmetric extension hierarchy [15, 16], which is presently one of the most powerful criteria, but hard to compute in practice due to its exponentially growing complexity with $k$.[??]
\end{theorem}

\subsubsection{Multipartite entanglement structures}
For multipartite quantum systems, it is crucial to identify not only the presence of entanglement but also its detailed structure.
An identification of the entanglement structure may thus provide us with a hint about where imperfections in the setup may occur, as well as where we can identify groups of subsystems that can still exhibit strong quantum-informationprocessing capabilities.

Given a $n$-qubit quantum system and its partition into $m$ subsystems, the \emph{entanglement structure} indicates how the subsystems are entangled with each other.
In some specific systems, such as distributed quantum computing[] quantum networks[] or atoms in a lattice, the geometric configuration can naturally determine the system partition.
% Moreover, for some systems, such as distributed quantum computing, multiple quantum processor, and quantum network, natural partition exists due to the system geometric configuration. 
Therefore, it is practically interesting to study entanglement structure under partitions.

\begin{definition}[fully entangled]\label{def:fully_entangled}
	An $n$-qubit quantum state $\dm$ is a \emph{fully entangled},
	if it is outside of the separable state set $S_b^{\ppartition_2}$ for any partition,
	$\dm \notin S_b^{\ppartition_2},\forall \ppartition_2 = \qty{A,\bar{A}}$.
	% \begin{equation}
	% 	\dm \notin S_b^{\ppartition_2},
	% 	\forall \ppartition_2 = \qty{A,\bar{A}}
	% \end{equation}
\end{definition}
GME is the strongest form of entanglement, that is, 
all qubits in the system are indeed entangled with each other.
\begin{definition}[genuine multipartite entanglement]\label{def:gme}
% \begin{definition}[genuine entangled]\label{def:genuinely_entangled}
	A state possesses \emph{genuine multipartite entanglement} (GME) if it is outside of $S_2$, and is (fully) $n$-separable if it is in $S_n$.
	A state possesses $\ppartition$-genuine entanglement if it is outside of $S_b^\ppartition$.
	A state $\dm$ possesses $\ppartition$-genuine entanglement iff $\dm\notin S_b^\ppartition$.
\end{definition}
% \begin{remark}
	Compared with genuine entanglement, multipartite entanglement structure still lacks a systematic exploration, due to the rich and complex structures of $n$-partite system.
	Unfortunately, it remains an open problem of efficient entanglement-structure detection of general multipartite quantum states.
% \end{remark}
\begin{definition}[Multipartite state]
	denote the partition $\ppartition_m = \qty{A_i}$
	and omit the index $m$ when it is clear from the context.
\end{definition}
define fully- and biseparable states with respect to a \emph{specific partition} $\ppartition_m$
\begin{definition}[fully separable]\label{def:fully_separable}
	An $n$-qubit pure state $\ket{\psi_f}$ is \emph{fully separable} \iff .
	An $n$-qubit pure state $\ket{\psi_f}$ is $\ppartition$-fully separable $\iff$ it can be written as 
	$\ket{\psi_f}=\otimes_i^m \ket{\phi_{A_i}}$.
	An $n$-qubit mixed state $\dm_f$ is $\ppartition$-fully separable $\iff$ it can be decomposed into a convex mixture of $\ppartition$-fully separable pure states.
	\begin{equation}
		\dm_f = \sum_i p_i \op{\psi_f^i}, (\forall i) ( p_i\ge 0, \sum_i p_i = 1) .
	\end{equation}
	P-bi-separable... $\separable_f^\ppartition \subset S_b^\ppartition$
\end{definition}
By going through all possible partitions, one can investigate higher level entanglement structures, such as entanglement intactness (non-separability), which quantifies how many pieces in the $n$-partite state are separated.

\begin{remark}
	P-... can be viewed as generalized versions of regular fully separable, biseparable, and genuinely entangled states, respectively.
	In fact, when $m=n$, these pairs of definitions are the same.
	By definitions, one can see that if a state is $P_m$-fully separable, it must be m-separable. Of course, an m-separable state might not be $P_m$-fully separable, for example, if the partition is not properly chosen.
\end{remark}
entanglement structure measures.
To benchmark our technological progress towards the generation of largescale genuine multipartite entanglement, it is thus essential to determine the corresponding entanglement depth.
\begin{definition}[Entanglement intactness, depth]
	the entanglement intactness of a state $\dm$ to be $m$, \iff $\dm\notin S_{m+1}$ and $\dm\in S_m$.
	When the entanglement intactness is 1, the state possesses \nameref{def:gme}; and when the intactness is $n$, the state is \nameref{def:fully_separable}.
	$k$-producible.
\end{definition}
% \begin{observation}
% \end{observation}
\begin{example}
	The \nameref{def:schmidt_measure} for any multi-partite \nameref{exm:ghz} states is 1, because there are just two terms.
	Schmidt measure for 1D, 2D, 3D-cluster state is $\floor{\frac{N}{2}}$.
	Schmidt measure of tree is the size of its minimal vertex cover[??].
\end{example}
\begin{example}[GHZ]\label{exm:ghz}
	bipartite: Bell states;
	nontrivial multipartite: tripartite.
	GHZ state: $\ket{\ghz}:=\frac{1}{\sqrt{2}}(\ket{0}^{\otimes n} + \ket{1}^{\otimes n} )$ (eight-photon) produce the five different entangled states (one from each entanglement structure/partition?): 
	\begin{equation*}
		\ket{\ghz_8},\ket{\ghz_{62}},\ket{\ghz_{44}},\ket{\ghz_{422}},\ket{\ghz_{2222}}.
	\end{equation*}
	% W state
	Schmidt rank, PPT criteria, entanglement witness
\end{example}

\begin{figure}[!ht]
	\centering
	% \begin{subfigure}{0.3\textwidth}
	% 	\centering
	% 	\includegraphics[width=.9\linewidth]{gme.jpg}
	% \end{subfigure}
	\begin{subfigure}{0.6\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{diagram.png}
	\end{subfigure}
	% \begin{subfigure}{0.3\textwidth}
	% 	\centering
	% 	\includegraphics[width=.8\linewidth]{sep.jpg}
	% \end{subfigure}
	% \begin{subfigure}{0.35\textwidth}
	% 	\centering
	% 	\includegraphics[width=.9\linewidth]{ppt.jpg}
	% \end{subfigure}
	\caption{(a) \nameref{def:entanglement_witness}, \nameref{thm:ppt}, \nameref{def:svm} (kernel)?. convex hull... }
	\label{fig:entangle}
\end{figure}

\subsubsection{Entanglement witness}\label{sec:entanglement_witness}

see \cref{fig:entangle} for relations.
entanglement detection \cite{guhneEntanglementDetection2009}.
\begin{definition}[entanglement witness]\label{def:entanglement_witness}
	Given an (unknown? known target state) quantum state (density matrix) $\dm$, the \emph{entanglement witness} $\ew$ is an obseverable such that
	\begin{equation}
		\Tr(\ew\dm) \ge 0 , \forall \text{ separable };\quad
		\Tr(\ew\dm) < 0 , \text{ for some entangled }
	\end{equation}
	\cite{terhalBellInequalitiesSeparability2000}, see \cref{fig:entangle}
\end{definition}
In a typical experiment one aims to prepare a pure state, $\ket{\psi}$, and would like to detect it as true multipartite entangled. 
While the preparation is never perfect, it is still expected that the prepared mixed state is in the proximity of $\ket{\psi}$. The usual way to construct entanglement witnesses using the knowledge of this state is
\begin{equation}
	\ew_{\psi} = c\identity - \op{\psi} 
	\label{eq:entanglement_witness}
\end{equation}
where $c$ is the smallest constant such that for every product state $\Tr(\dm\ew)\ge 0$
\begin{remark}
In order to measure the witness in an experiment, it must be decomposed into a sum of locally measurable operators. The number of local measurements in these decompositions seems to increase exponentially with the number of qubits.[??]
\end{remark}
\begin{example}[entanglement witness for GHZ]
	three-qubit GHZ state 
	\cite{tothDetectingGenuineMultipartite2005}
	\begin{equation}
		\ew_{\ghz_3} := \frac{3}{2} \identity - \sx^{(1)}\sx^{(2)}\sx^{(3)}
		- \frac{1}{2} \qty[
			\sz^{(1)} \sz^{(2)} + 
			\sz^{(2)} \sz^{(3)} + 
			\sz^{(1)} \sz^{(3)} 
		]
	\end{equation}
	This witness requires the measurement of the $\qty{\sx^{(1)},\sx^{(2)},\sx^{(3)}}$ and $\qty{\sz^{(1)},\sz^{(2)},\sz^{(3)}}$ settings.
	The projector based witness $\ew_{\ghz_3}=\identity/2 - \op{\ghz}$ requires four measurement settings.
	detect genuine $n$-qubit entanglement close to $\ghz_n$
	\begin{equation}
		\ew_{\ghz_n} = (n-1) \identity - \sum_{k=1}^n S_k^{(\ghz_n)}
	\end{equation}
	$\stbz_k$ is the \nameref{def:stabilizer} ... \cite{tothEntanglementDetectionStabilizer2005}
	Detecting Genuine Multipartite Entanglement with Two Local Measurements \cite{tothDetectingGenuineMultipartite2005}
\end{example}
\begin{question}
	how far/close to the target state (entanglement witness), noise limit?
\end{question}

It is natural to ask how nonlinear entanglement witness \cite{guhneNonlinearEntanglementWitnesses2006}  and the \nameref{def:kernel} method (nonlinear boundary) in machine learning can be applied. 

\begin{proposition}\label{thm:entanglement_witness_gme}
	Given a state $\ket{\psi}$,
	the \nameref{def:entanglement_witness} operator $\ew_{\psi}$ can witness \nameref{def:gme}  near $\ket{\psi}$ with $c=5/8$ in \cref{eq:entanglement_witness}
	% \nameref{def:genuinely_entangled}
	% \begin{equation}
	% 	\ew_{\psi} = \frac{5}{8}\identity - \op{\psi} 
	% \end{equation}
	that is, $\expval{\ew_{\psi}}\ge 0$ for any separable state in $S_b$.
\end{proposition}
If the \nameref{def:fidelity} (quantum kernel?) of the prepared state $\dm_{\text{pre}}$ with the target state $\ket{\psi}$, i.e., $\Tr(\dm_{pre}\op{\psi})$, exceeds $5/8$, $\dm_{pre}$ possesses GME.
It is generally difficult to evaluate the quantity $\Tr(\dm_{pre}\op{\psi})$ by the direct projection on $\ket{\psi}$, as it is an entangled state.

A usual approach for detecting entanglement is using Bell inequalities [??]
\begin{definition}[Bell inequality]\label{def:bell_inequality}
	CHSH inequality (game) ...;
	Bell inequalities for graph states $\abs{\sum_{\sigma\in S} \expval{\sigma}}\le C?$...
\end{definition}
Another approach for detecting multipartite entanglement is using entanglement witnesses.
Different Bell inequalities can be regarded as entanglement witness for different types of entanglement in a multi-party entangled state.
These witnesses can be quite useful to detect entanglement in the vicinity of graph states.
\begin{problem}[separability]\label{prm:separable}
	given (input) an \textbf{unknown} state, to determine (output) separability.
\end{problem}
\begin{problem}[Entanglement witness with prior]
	% \cite{zhouDetectingMultipartiteEntanglement2019}
	Entanglement witness	
		\begin{itemize}
		\item \textbf{Input}: a \textbf{known} state $\ket{\psi}$, with noise
		\item \textbf{Output}: separable or not ??? $\separable_f^\ppartition$ ? $\separable_b^\ppartition$ 
		% (decision problem?? find problem)
	\end{itemize}
	\textbf{difficulty}: multi($n$)-partite, high-dimensional (qudit) \cite{sciaraUniversalPartiteLevel2019}, pure/mixed state, with/out prior knowledge, universal?, non-stabilizer \cite{tothEntanglementDetectionStabilizer2005}, certain partition
\end{problem}
\begin{remark}[universal entanglement witness]
	\cite{sciaraUniversalPartiteLevel2019}
	% Since the witness tests for a specif state, a successful measurement of the operator also provides information about the state structure and phase, rather than only conﬁrming the presence of entanglement. 
	For example, a witness specifically designed for a four-qubit compact cluster state [16] conﬁrms, when its expectation value is negative, the presence of that particular state having a very speciﬁc density function, while a positive measured expectation value of that operator only provides information that the tested state is not a compact cluster state. Indeed, the same witness, if applied to a four-qubit linear cluster or Greenberger-Horne-Zeilinger (GHZ) [17] states, would result in a positive measured expectation value, even though these two states are both highly entangled [17, 18]. 
	Hence, a witness is a threshold test that can only detect the presence of a speciﬁc state. 
	In contrast to an entanglement monotone (e.g. the entanglement entropy [6]), which determines the amount of entanglement, a witness cannot be used to quantify entanglement.	
\end{remark}
\begin{problem}[Certify entanglement]
	Multipartite entanglement-structure detection
	\begin{itemize}
		\item \textbf{Input}: an (actual) state $\dm'$ from experiment that is close to a \textbf{known/target} (general multipartite) state $\ket{\psi}$,
		certain partition?
		\item \textbf{Output}: the certified lower-order entanglement among several subsystems could be still useful for some quantum information tasks.
		entanglement structure
	\end{itemize}
\end{problem}

\subsubsection{Graph state}
graph state is an important (large?) class of multipartite states in quantum information.
Typical graph states include cluster (lattice) states, \nameref{exm:ghz} states, and the states involved in error correction (toric code?).
% cluster state is the special case of graph state.
It worth noting that 2D cluster state is the universal resource for the measurement based quantum computation (MBQC) \cite{briegelMeasurementbasedQuantumComputation2009}.
\begin{definition}[graph state]\label{def:graph_state}
	Given a simple graph (undirected, unweighted, no loop and multiple edge) $G=(V,E)$, a graph state is constructed as 
	from the initial state $\ket{+}^{\otimes n}$ corresponding to $n$ vertices.
	Then, apply controlled-Z gate to every edge, that is 
	\begin{equation}
		\ket{G}:=\prod_{(i,j)\in E}\textsf{cZ}_{(i,j)} \ket{+}^{\otimes n}
	\end{equation}
	% \begin{itemize}
	% 	\item vertices: $\ket{+}^{\otimes n}$
	% 	\item edges: apply controlled-Z to every edge,
	% 	that is $\ket{G}=\prod_{(i,j)\in E}\textsf{cZ}_{(i,j)} \ket{+}^{\otimes n}$
	% \end{itemize}
\end{definition}
\begin{remark}
	An $n$-partite(qubit) graph state can also be uniquely determined by $n$ independent stabilizers, 
	$S_i:= X_i \bigotimes_{j\in n}Z_j$, 
	which commute with each other and $\forall i,S_i\ket{G}=\ket{G}$.??
	The graph state is the unique eigenstate wtih eignevalue of +1 for all the $n$ stabilizers.
	As a result, a graph state can be written as a product of stailizer projectors, $\op{G}=\prod_{i=1}^n \frac{S_i +\identity}{2}$.
	stabilizer formalism
	\nameref{sec:stabilizer_formalism}?; 
\end{remark}
% \begin{question}
% \end{question}
\begin{figure}[!ht]
	\centering
	\begin{subfigure}{0.3\textwidth}
	\centering
	\begin{tikzpicture}[rotate=18]
		\SetGraphUnit{2} 
		\GraphInit[vstyle=Normal] 
		% \renewcommand*{\VertexInnerSep}{8pt} \renewcommand*{\EdgeLineWidth}{3pt} \renewcommand*{\VertexBallColor}{blue!50} 
		\Vertices{circle}{A,B,C,D,E} 
		\Edges(A,B,C,D,E,A,C,E,B,D,A) 
	\end{tikzpicture}
	\caption{complete graph $K_5$}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
	\centering
	\begin{tikzpicture}[rotate=90] 
		\GraphInit[vstyle=Hasse] 
		% \Vertices[unit=2]{circle}{A,B,C,D} 
		% \coordinate (Z) at (intersection of A--C and B--D); 
		\Vertices[unit=2]{circle}{A,B,C,D,E,F,G,H} 
		\coordinate (Z) at (intersection of A--E and B--F); 
		\Vertex[Node]{Z}% voir option node
		\Edges(A,Z)
		\Edges(B,Z)
		\Edges(C,Z)
		\Edges(D,Z)
		\Edges(E,Z)
		\Edges(F,Z)
		\Edges(G,Z)
		\Edges(H,Z)
		\AddVertexColor{red}{A,B,C,D,E,F,G,H} 
		% \AddVertexColor{red}{A,B,C,D} 
		\AddVertexColor{blue}{Z} 
	\end{tikzpicture}
	\caption{star graph (2-colorable) - GHZ}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
	\centering
	\begin{tikzpicture}[rotate=18,scale=1.0]
		\SetGraphUnit{1} 
		\GraphInit[vstyle=Welsh] 
		% \renewcommand*{\VertexLineWidth}{2pt}
		% \renewcommand*{\VertexInnerSep}{8pt} 
		% \renewcommand*{\EdgeLineWidth}{3pt} 
		% \renewcommand*{\VertexBallColor}{blue!50} 
		\Vertices{circle}{A,B,C,D,E} 
		\Edges(A,D,B,E,C,A) 
		\SetGraphUnit{2} 
		\Vertices{circle}{a,b,c,d,e} 
		\Edges(a,b,c,d,e,a) 
		\Edges(A,a)
		\Edges(B,b)
		\Edges(C,c)
		\Edges(D,d)
		\Edges(E,e)
		\AddVertexColor{red}{b,d,A,E} 
		\AddVertexColor{blue}{c,B,a}
		\AddVertexColor{green}{C,D,e}
	\end{tikzpicture}
	% \caption{A 3-coloring of the Petersen graph}
	\caption{Petersen graph}
	\end{subfigure}
	\caption{graph states}
	\label{fig:graph_state}
\end{figure}
\begin{example}[graph states]
	Any connected graph state is \nameref{def:fully_entangled} state.
	The \nameref{exm:ghz} state corresponds to the star graph and the complete gtaph (\cref{fig:graph_state}). 
	This is easily seen by applying Hadamard unitaries $\U_\hdm^{V\backslash a}$ to all but one qubit $a$ in the GHZ-state, 
	which yields the star graph state with $a$ as the central qubit.
	(line, ring; 
	hypercube, Petersen graph; 
	cluster state in two dimensinos, which corresponds to a rectangular lattice.)
	The Petersen graph is not LC-equivalent to its isomorphism (exchanging the labels at each ed of the five ``spokes"). However, the lists of Schmidt ranks (or, equivalently, the connectivity functions) of these graphs coincide.
	The class of CSS (error correction) states corresponds to the class of 2-\nameref{exm:colorable} graphs.
	\cite{heinEntanglementGraphStates2006}
\end{example}
% \begin{question}
% 	efficient? meaningful encoding of graph data/input??
% 	Hamiltona cycle of a graph state? vertex cover
% \end{question}
% \begin{problem}[Entanglement structure detection]
% \end{problem}
% \begin{observation}
% 	Any connected graph state is fully entangled m-particle state
% \end{observation}

\begin{remark}[??]
	The entanglement \nameref{def:entropy} $S( \dm_A )$ equals the rank of the adjacency matrix of the underlying bipartite graph, which can be efficiently calculated.
	For graph states, the reduced density matrices can be represented efficiently in terms of their stabilizer elements or their adjacency matrix.
	% \cite{heimQuantumClassicalAnnealing2015}
\end{remark}
\begin{proposition}[\cite{zhouDetectingMultipartiteEntanglement2019}]
	Given a graph state $\ket{G}$ and a partition $\mathcal{P}=\qty{A_i}$, the \nameref{def:fidelity} between $\ket{G}$ and any \nameref{def:fully_separable} is upper bounded by
	\begin{equation}
		\Tr(\op{G} \dm_f) \le \min_{\qty{A,\bar{A}}} 2^{-S(\dm_A)}
	\end{equation}
	where $S(\dm_A)$ is the von Neumann \nameref{def:entropy} of the reduced density matrix $\dm_A=\Tr_{\bar{A}}(\op{G})$.
\end{proposition}
\begin{remark}
	LU, LC equivalence, local operations and classical communication (LOCC)
\end{remark}
the entanglement in a graph state is related to the topology of its underlying graph.
\begin{proposition}[Entanglement of graph state]
	\cite{heinEntanglementGraphStates2006}.
	witness; bounds; \nameref{def:graph_property}? vertex cover?
	Hamiltonian cycle of a graph state? 
\end{proposition}
generalize \cite{zhangEfficientEntanglementGeneration2021}
stabilizer state, neural network state \cite{gaoEfficientRepresentationQuantum2017}?
\begin{proposition}[Entanglement witness for graph state]
	\nameref{def:bell_inequality}
	\begin{equation}
		\ew = \frac{C}{2^N} \identity_V - \op{G}
	\end{equation}
	Let $\ket{G}$ be a graph state corresponding to a connected graph. Then
	\begin{equation}
		\ew_1^{ab} = \identity_V - K_a - K_b
	\end{equation}
	is an entanglement witness for the $\ket{G}$ that detects entanglement in the reduced state $\dm_G^A (A=N_a\cup N_b \cup \qty{a,b})$ with only two measurement settings and thus can rule out full separability of the total graph state???. 
	The entanglement witness 
	\begin{equation}
		\ew_2 = (N-1)\identity_V - \sum_{a\in V} K_a
	\end{equation}
	detects \nameref{def:gme}. 
\end{proposition}
\begin{question}
	for which case, $C$ is hard to compute? non-stabilizer state? SWAP?
\end{question}
\begin{theorem}
	k local measurements. Here, k is the chromatic number (minimal \nameref{exm:colorable}) of the corresponding graph, typically, a small constant independent of the number of qubits.
\end{theorem}
\begin{proposition}[Bounds to the Schmidt measure of graph states]
	For any graph state $\ket{G}$, the \nameref{def:schmidt_measure} $E_A$ is bounded from below by the maximal Schmidt rank $\textup{SR}_{\max}$ and from above by the Pauli persistency PP or the minimal vertex cover, i.e.
	\begin{equation}
		\textup{SR}_{\max} (G) \le E_S(\ket{G}) \le \textup{PP}(G) \le \textup{VC}(G).
	\end{equation}
	???
\end{proposition}


\subsection{Tomography and trace estimation}
% \label{sec:shadow_tomography}
The brute force approach is to fully characterize a system by performing quantum state tomography and calculating separability measures from the recovered density matrix.
Intuitively, a general tomography \cite{altepeterPhotonicStateTomography2005} that extract (recover) all information of a state requires exponential copies (samples/measurements).
\begin{problem}[full tomography]\label{prm:full_tomography}
	In contrast to \nameref{prm:shadow_tomography}, we refer to \emph{full tomography} here
	\begin{itemize}
		\item \textbf{Input}: Given a \textbf{unknown} $N$-dimensional mixed state $\dm$
		\item \textbf{Output}: a complete description? of $\dm$ (decomposition coefficients) with error?
		Stokes parameter $S_i\equiv \Tr(\hat{\sigma}_i \dm)$
		\begin{equation}
			\dm = \frac{1}{2^n} \sum_{i_1,i_2,\dots,i_n=0}^3
			S_{i_1,i_2,\dots,i_n} 
			\hat{\sigma}_{i_1} \otimes \hat{\sigma}_{i_2} \otimes \dots \otimes \hat{\sigma}_{i_n} 
			\label{eq:stokes_tomography}
		\end{equation}
	\end{itemize}
\end{problem}
However, tomography is experimentally and computationally demanding; for a state consisting of $N$ particles, with each residing in a $d$-dimensional Hilbert space, we would have to perform $M = \bigO(d^{2N})$ measurements.
\begin{theorem}[lower bound of \nameref{prm:full_tomography}?\cite{haahSampleoptimalTomographyQuantum2017}]
	Known fundamental lower bounds [66, 73] state that classical shadows of exponential size (at least) $T = \Omega( 2^n / \epsilon^2)$ are required to $\epsilon$-approximate $\dm$ in trace \nameref{def:distance}.
\end{theorem}
\begin{definition}[fidelity]\label{def:fidelity}
	Given a pair of states (target $\dm$ and prepared $\dm'$), 
	Uhlmann fidelity $F(\dm,\dm') : = \Tr(\sqrt{\sqrt{\dm}\dm'\sqrt{\dm}})\equiv\norm{\sqrt{\dm}\sqrt{\dm'}}_1$, where $\sqrt{\dm}$ dentoes the positive semidefinite square root of the operator $\dm$.
	For any mixed state $\rho$ and pure state $\ket{\psi}$, $F(\dm,\op{\psi})=\sqrt{\mel{\psi}{\dm}{\psi}}\equiv \sqrt{\Tr(\dm\op{\psi})}$ which can be obtained by the Swap-test[?].
	% \begin{equation}
	% 	F(\ket{\psi},\ket{\psi'}) :=
	% \end{equation}
	% \begin{equation}
	% 	F(\rho,\rho') : = \Tr \sqrt{\sqrt{\rho}\rho'\sqrt{\rho}}
	% \end{equation}
\end{definition}
\begin{definition}[distance]\label{def:distance}
	For mixed states, trace distance $d_{\tr}(\dm,\dm') : = \frac{1}{2} \norm{\dm-\dm'}_1$.
	For pure states, $d_{\tr}(\ket{\psi},\ket{\psi'}) : = \frac{1}{2}\norm{\op{\psi} -\op{\psi'}}_1 = \sqrt{1-\abs{\ip{\psi}{\psi'}}^2}$.
	% \begin{equation}
	% 	d_{tr}(\rho,\rho') : = \frac{1}{2} \norm{\rho-\rho'}_1
	% \end{equation}
	fidelity and trace distance are related by the inequalities
	\begin{equation}
		1-F\le D_{\tr}(\dm,\dm') \le \sqrt{1-F^2}
	\end{equation}
\end{definition}
\begin{definition}[norm]\label{def:norm}
	Schatten p-norm $\norm{x}_p:= (\sum_i \abs{x_i}^p)^{1/p}$.
	Euclidean norm $l_2$ norm;
	Spectral (operator) norm $\norm{\vbx}_{\infty}$;
	Trace norm $\norm{A}_{\Tr}\equiv\norm{A}_{1}:=\Tr(\abs{A})\equiv\Tr(\sqrt{A^\dagger A})$, $\abs{A}:=\sqrt{A^\dagger A}$, $p=1$;
	Frobenius norm $\norm{A}_{F}:=\sqrt{\Tr(A^\dagger A)}$, $p=2$;
	Hilbert-Schmidt norm $\norm{A}_{HS}:=?\sqrt{\sum_{i,j} A_{ij}^2 }=?\sum_{i\in I}\norm{Ae_i}_H^2$;
	Hilbert-Schmidt inner product $\expval{A,B}_{\textup{HS}}:=\Tr(A^\dagger B)$,
	Frobenius inner product $\expval{A,B}_{\textup{F}}:=\Tr(A^\dagger B)$?
	(in finite-dimensionala Euclidean space, the HS norm is identical to the Frobenius norm)
\end{definition}
% \begin{problem}[Fidelity estimate]
% 	defined as follows
% 	\begin{itemize}
% 		\item \textbf{Input}: Given two density matrices $\dm$ and $\dm'$, 
% 		\item \textbf{Output}: \nameref{def:fidelity} with error $\epsilon$
% 	\end{itemize}
% \end{problem}
In quantum mechanics, interesting properties are often linear functions of the underlying density matrix $\dm$.
For example, the fidelity with a pure target state, entanglement witnesses fit this framework.
\begin{problem}[trace estimation]\label{prm:trace_estimation}
	related problems defined as follows
	\begin{itemize}
		\item \textbf{Input}: Given an observable (Hermitian) $\ob$ and (copies of) a mixed state $\dm$ or several states ($\dm',\dots,\dm_m$), 
		\item \textbf{Output}: with error $\epsilon$ measured by trace \nameref{def:distance} (\nameref{def:fidelity}...)
		\begin{itemize}
			\item linear function (mostly):
			the expectation value $\expval{\ob}=\Tr(\ob \dm) $; 
			\nameref{def:entanglement_witness} $\Tr(\ew\dm)$;
			\nameref{prm:shadow_tomography} $\Tr(E_M\dm) = \expectation[E_M] = \probability[E_i \text{ accept } \dm]$??;
			\nameref{prm:full_tomography};
			$\Tr(\ob\mathcal{E}(\op{\psi}))$ where $\mathcal{E}$ is a CPTP (completely positive and trace preserving) map
			two-point correlation $\expval{O_iO_j}$

			\item nonlinear function:
			\nameref{def:entropy} (non-linear); quadratic $\Tr(\ob \dm_i \otimes \dm_j)$;
			\nameref{def:fidelity} $F(\dm,\dm')$, \nameref{def:distance}??;
% A nonlinear function of $\dm$ such as \nameref{def:entanglement_entropy}, may also be of interest.

			\item multivariate: 
			% (quantum kernel, multivariate ??...)
			\nameref{def:quantum_kernel} $\Tr(\dm\dm')$;
			multivariate $\Tr(\dm_1 \cdots \dm_m)$, nonlinear function?? linear;
		\end{itemize}
	\end{itemize}
	% The task of estimating quantities like 
	% \begin{equation}
	% 	\Tr(\rho_1 \cdots \rho_m)
	% 	\tag{multivariate traces}
	% \end{equation}
	% given access to copies of the quantum states $\rho_1$  through $\rho_m$.
\end{problem}

Nevertheless, we usually only need specific properties of a target state rather than full classical descriptions about the state.
This enables the possibility to shadow tomography.
\begin{problem}[shadow tomography]\label{prm:shadow_tomography}
	\emph{shadow tomography}
	\begin{itemize}
		\item \textbf{Input}: an \textbf{unknown} $N$-dimensional mixed state $\rho$, $M$ known 2-outcome measurements $E_1,\dots,E_M$
		\item \textbf{Output}: estimate $\probability[E_i \text{ accept } \dm]$ to within additive error $\epsilon$, $\forall i\in [M]$, with $\ge 2/3$ success probability.	
	\end{itemize}
\end{problem}
\begin{theorem}[bounds of shadow tomography \cite{aaronsonShadowTomographyQuantum2018}]\label{thm:shadow_tomography}
	It is possible to do \nameref{prm:shadow_tomography} using $\tilde{\bigO}(\frac{\log^4 M\cdot \log N}{\epsilon^4})$ copies. [no construction algorithm?]
	sample complexity lower bound $\Omega(\log (M) \cdot \epsilon^{-2})$, 
\end{theorem}
more details in \cref{sec:classical_shadow}
\begin{remark}[compare shadow tomography and classical shadow \cite{huangPredictingManyProperties2020}]
	While very efficient in terms of samples, Aaronson's procedure is very demanding in terms of quantum hardware — a concrete implementation of the proposed protocol requires \textbf{exponentially long quantum circuits} that act collectively on all the copies of the unknown state stored in a quantum memory.??
\end{remark}

\section{Classical, data-powered, and quantum algorithms}
In this paper, we focus on the entanglement structure dectection for graph states.
\begin{problem}[detect graph state entanglement structure?]
	problem without training data
	\begin{itemize}
		\item \textbf{Input}: a graph $\graph$ encoding in a graph state $\ket{\graph}$;
		adjacency matrix $A$?
		\item \textbf{Output}: entanglement structure??
	\end{itemize}
\end{problem}
with training data: 
\textbf{features}: classical shadow? raw data? quantum data, label: entangled?
% \begin{itemize}
% 	\item \textbf{features}: classical shadow?
% 	\item label: 
% \end{itemize}

\begin{definition}[input model]\label{def:input_model}
	several common input (encoding) models in quantum algorithms: 
	\begin{itemize}
		% \item qubit (basic) encoding?: given a vector $\vb{z}\in\integer^d$, 
		% $\ket{\vb{z}}=\bigotimes_i^d \ket{\vbx_i}$ where $\vbx_i$ is the binary representation of $z_i$,
		% need $\bigO(d\cdot \log(\max(z_i)))$ (not space efficient)

		% \item phase encoding?

		\item \textbf{amplitude encoding}: given a normalized vector $\vbx\in\realnumber^d$, the quantum state $\ket{\vbx}=\sum_z^d x_z\ket{z}$. 
		need $\log(d) $ qubits for a data point; 
		In general, it is hard to prepare such state. (subject to dequantization \cite{tangQuantumPrincipalComponent2021}). 
		typical encoding method for quantum machine learning for classical problems (such as image classification).
		% qubit (basic) encoding (inefficient? space)

		\item \textbf{unitary encoding}: quantum simulation (Hamiltonian); quantum random walk (adjacency matrix); oracle (controlled) unitary, e.g., quantum phase estimation;
		\nameref{def:graph_state} encoding (discrete, efficient in space/time?, isomorphism?)

		\item \textbf{quantum data}: quantum state $\ket{\psi}$ or $\dm$ from real-world experiments or designed quantum circuits $\U$.
		no input problem? more efficient? for quantum algorithms

		% \item graph state encoding: \nameref{def:graph_state}, discrete, efficient? space (time), isomorphism?

		% \item (quantum) oracle: $\oracle \ket{i,a}=\ket{i,a+x_i}$; quantum oracle: unitary and controlled unitary
	\end{itemize}
\end{definition}
\begin{question}
	how to relate graph state entanglement to \nameref{prm:graph_property_test}
	..??.
\end{question} 
\begin{definition}[graph property]\label{def:graph_property}
	% The setting of graph property testing provides a natural class of partial graph properties.
	monotone ...
\end{definition}
\begin{example}[colorable]\label{exm:colorable}
	$k$-colorable is a graph property, i.e., allow for a coloring of the vertices with $k$ colors such that no two adjacent vertices have the same color.
	A graph is bipartite $\iff$ 2-colorable.
	other graph properties: isomorphism; vertex cover; Hamiltonian cycle ...
\end{example}
\begin{problem}[graph property test]\label{prm:graph_property_test}
	\textbf{promise}: the input graph either has a property, or is $\epsilon$-far from having the property, meaning that we must change at least an $\epsilon$ fraction of the edges to make the property hold.
\end{problem}
\begin{theorem}[bounds for graph property test]
\end{theorem}
\begin{question}
	\cite{montanaroSurveyQuantumProperty2018}
	Is there any graph property which admits an exponential quantum speed-up?
	\cite{ben-davidSymmetriesGraphProperties2020}
	depends on input model (query adjacency matrix/list)
	% quantum algorithms (bounds) for graph properties \cite{ben-davidSymmetriesGraphProperties2020}
\end{question}
Graphs is another kind of data which is fundamentally different from a real value vector because of vertex-edge relation and graph isomorphism.
So, graph kernel \cite{kriegeSurveyGraphKernels2020} need additional attention.
\begin{definition}[graph kernel]\label{def:graph_kernel}
	given a pair of graphs $(\graph,\graph')$,
	\emph{graph kernel} is $\kernel (\graph,\graph')  =$.
	% \begin{equation}
	% \end{equation}
	quantum graph kernel $\kernel (\graph,\graph')  = \abs{\ip{\graph}{\graph'}}^2$ ??
	\cite{baiQuantumJensenShannon2015}	
\end{definition}

\subsection{Classical shadow and machine learning}
related works
\begin{itemize}
	\item separability classifier by classical neural network \cite{luSeparabilityEntanglementClassifierMachine2018}:
	input: sythetic random density matrices;
	output: a classical classifier for \nameref{def:bipartite_separable} (independent of state??).
	The idea is to feed the classifier by a large amount of sampled trial states (feature: synthetic density matrix with noise flatten as a real vector $\vbx\in\realnumber^{d_A^2d_B^2-1}$) as well as their corresponding class labels (separable or entangled by \nameref{thm:ppt}, CHA), and then train the classifier to predict the class labels of new states that it has not encountered before.
	Previous methods \textbf{only detect a limited part of the state space}, e.g. different entangled states often require different \nameref{def:entanglement_witness}. In contrast, this classifier can handle a variety?? of input states once properly trained \cref{fig:entangle}.

	\item \nameref{def:classical_shadow} \cite{huangPredictingManyProperties2020}: estimate entanglment witness (fixed but unknown target state, e.g., tripartite GHZ)
	Entanglement verification. Fidelities with pure target states can also serve as (bipartite) entanglement witnesses. For every (bipartite) entangled state $\dm$, there exists a constant $\alpha$ and an observable $\ob = \op{\psi}$ such that $\Tr(\ob \dm ) > \alpha \ge \Tr(\ob \dm_s )$, for all (bipartite) separable states $\dm_s$. Establishing $\Tr(\ob \dm ) > \alpha$ verifies the existence of entanglement in the state $\dm$. Any $\ob = \op{\psi}$ that satisfies the above condition is known as an entanglement witness for the state $\dm$. 
	\textbf{Classical shadows (Clifford measurements) of logarithmic size allow for checking a large number of potential entanglement witnesses simultaneously}.
	Directly measuring M diﬀerent entanglement witnesses requires a number of quantum measurements that scales (at least) linearly in $M$. In contrast, classical shadows get by with $\log(M)$-many measurements only.
	classical shadows are based on random Clifford measurements and do not depend on the structure of the concrete witness in question. In contrast, direct estimation crucially depends on the concrete witness in question and may be considerably more diﬃcult to implement.

	\item classical SVM: An SVM allows for the construction of a hyperplane $\expval{\ew}=\sum_k w_k \vbx_{k}$ that clearly delineates between separable states and the target entangled state (bipartite and \textbf{tripartite qubit and qudit}); this hyperplane is a \textbf{weighted sum of observables (`features') whose coefficients are optimized during the training of the SVM}.
	This method the ability to obtain witnesses that require only local measurements even when the target state is a \textbf{non-stabilizer state} $W$ state (normally need nonlocal measurements).
	feature: $\vbx_{\vec{k}}$ expectation of Pauli strings.
	the training of an SVM is convex; if a solution exists for the given target state and ansatz, the optimal SVM 2 will be found.
	this SVM formalism allows for the programmatic removal of features, i.e., reducing the number of experimental measurements, in exchange for a lower tolerance to white noise, in a manner similar to [??].

	\item classical machine learning (SVM, NN) with \nameref{def:classical_shadow} \cite{huangProvablyEfficientMachine2021}??: classify phase, predict ground state, entanglement?

\end{itemize}

\subsubsection{Classical shadow}\label{sec:classical_shadow}
Inspired by Aaronson's shadow tomography \cite{aaronsonShadowTomographyQuantum2018}, Huang et. al \cite{huangPredictingManyProperties2020} introduce classical shadow.
A classical shadow is a succinct classical description of a quantum state, which can be extracted by performing reasonably simple single-copy measurements on a reasonably small number of copies of the state.
The classical shadow attempts to approximate this expectation value by an empirical average over $T$ independent samples, much like Monte Carlo sampling approximates an integral.
\begin{definition}[classical shadow]\label{def:classical_shadow}
	classical shadow (snapshots) $\dm_{cs}$
	\begin{equation}
		\dm_{cs} = \mathcal{M}^{-1} \qty(U^\dagger \op{\hat{b}} U)
	\end{equation}
	such that we can predict the linear function with classical shadows
	\begin{equation}
		o_i = \Tr(O_i \dm_{cs})
		\text{ obeys }
		\expectation[o] =\Tr(O_i \dm)
	\end{equation}
\end{definition}
% \begin{remark}
The classical shadow size required to accurately approximate all reduced $r$-body density matrices scales exponentially in subsystem size $r$, but is independent of the total number of qubits $n$.
% \end{remark}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \Input{an (unknown) density matrix $\dm$ (many copies)}
	% , observables $\ob$...
    \Output{\nameref{def:classical_shadow} $\dm_{cs}$}
    \BlankLine
    \For{ $i = 1,2, \ldots, N$} {
        $\dm\mapsto \U\dm \U^\dagger$ \tcp*{apply a random unitary to rotate the state}
		$\mapsto \ket{b}$... \tcp*{perform a computational-basis measurement}
		$\dm_{cs}=\mathcal{M}^{-1}\qty(U^\dagger \op{b}) U$ \tcp*{measurement outcome $\ket{b}\in \qty{0,1}^n $, $\mathcal{M}$ quantum channel}
        % \tcc{comment in a new line}
    % {\Return ?}
    }
    \Return $S(\dm,N)=\qty{\dm_{cs_1}=\mathcal{M}^{-1}\qty(\U_1^\dagger\op{b_1}\U_1),\dots,\dm_{cs_N}}$ \tcp*{call this array the classical shadow of $\dm$}
    \caption{Classical Shadow (tomography)}
    \label{alg:classical_shadow}
\end{algorithm}
A classical shadow is created by repeatedly performing a simple procedure: Apply a unitary transformation $\dm \mapsto \U \dm \U^\dagger$, and then measure all the qubits in the computational basis. The number of times this procedure is repeated is called the size of the classical shadow. The transformation $U$ is randomly selected from an ensemble of unitaries, and diﬀerent ensembles lead to diﬀerent versions of the procedure that have characteristic strengths and weaknesses.
Classical shadows with size of order $\log(M)$ suﬃce to predict $M$ target functions $\qty{\ob_1,\dots,\ob_M}$.
\begin{lemma}
	predict linear function with shadow shadow:
	the variance
	\begin{equation}
		\variance[o] = \expectation[(o-\expectation[o])^2]
		\le \norm{O - \frac{\Tr(O)}{2^n} \identity}^2_{\shadow}
	\end{equation}
\end{lemma}
\begin{theorem}\label{thm:classical_shadow_upper}
	Fix a measurement primitive $\mathcal{U}$??, a collection $\qty{\ob_1,\dots,\ob_M}$ of $2^n\times 2^n$ Hermitian matrices and accuracy parameters $\epsilon,\delta\in[0,1]$.
	Set 
	\begin{equation}
		K = 2\log (2M/\delta)
		,\quad
		N = \frac{34}{\epsilon^2}\max_{1\le i\le M} \norm{\ob_i-\frac{\Tr(O_i)}{2^n} \identity}^2_{\shadow}
	\end{equation}
	where $\norm{\cdot}_{\shadow}$ is \nameref{def:shadow_norm}. 
	Then, a collection of NK independent classical shadows allow for accurately predicting all features via median of means prediction
	\begin{equation}
		\abs{o_i (N,K), -\Tr(O_i \dm)}\le \epsilon,\; \forall i\le i \le M
	\end{equation}
	wieth probability at least $1-\delta$.
	$o_i(N,K)=\textup{median}\qty{\Tr(\ob_i\dm_{(1)}),\dots,\Tr(\ob_i\dm_{(K)})}$
	% sample complexity
	% \begin{equation}
	% 	N_{tot} = \bigO \qty(
	% 		\frac{\log (M)}{\epsilon^2} \max_{1\le i\le M} 
	% 		\norm{O_i - \frac{\Tr(O_i)}{2^n} \identity}^2_{\shadow}
	% 	)
	% \end{equation}
\end{theorem}
\begin{definition}[shadow norm]\label{def:shadow_norm}
	$\norm{\cdot}_{\shadow}$ is shadow norm that only depends on the measurement primitive:
	\begin{equation}
		\norm{O}_{\shadow} =\max_{\sigma:state} \qty(
			\expectation_{U\sim \mathcal{U}}
			\sum_{b\in \qty{0,1}^n } \mel{b}{\U\sigma\U^\dagger}{b} 
			\mel{b}{\U\mathcal{M}^{-1}(O) \U^\dagger}{b}^2 
		)^{1/2}
	\end{equation}
	(nonnegative, homogeneous, triangle inequality)
\end{definition}

\begin{theorem}[Pauli/Clifford measurements]\label{thm:classical_shadow_lower}
	Any procedure based ona fixed set of single-copy local measurements that can predict,
	with additive error $\epsilon$, $M$ arbitrary $k$-local linear function $\Tr(\ob_i\dm)$,
	requires at least (lower bound)
	$\Omega(\log(M) 3^k/\epsilon^2)$ copies of the state $\dm$.
	$\Omega(\log(M) \max_i\Tr(\ob_i^2)/\epsilon^2)$ 
\end{theorem}
Consider a simple family of entanglement witnesses with compatible structure:  (ansatz??)
\begin{equation}
	O:= O(V_A,V_B,V_C)=V_A\otimes V_B \otimes V_C \op{\psi_{\ghz}^+} V_A^\dagger\otimes V_B^\dagger \otimes V_C^\dagger
\end{equation}
the single-qubit unitaries $V_A,V_B,V_C$ parametrize differenet witnesses.
for any state $\dm_s$ with only bipartite entanglement, $\Tr(\ob \dm_s)\le 0.5$, 
while for any state $\dm_s$ with at most $W$-type entanglement, $\Tr(\ob \dm_s)\le 0.75$.
Therefore verifying that $\Tr(\ob \dm)\ge 0.5$ certifies that $\dm$ has tripartite entanglement, while $\Tr(\ob \dm)> 0.75$ certifies that $\dm$ has $\ghz$-type entanglement.


\subsubsection{training data and classical kernel methods}

$\sigma_T(\dm(x_l))$ is the classical shadow representation of $\dm(x_l)$, 
a $2^n\times 2^n$ matrix that reproduces $\dm(x_l)$ in expectation over random Pauli measurements.
\begin{equation}
	\qty{x_l\to\sigma_T(\dm(x_l))}_{l=1}^N
\end{equation}
\begin{definition}[shadow kernel]\label{def:shadow_kernel}
	given two density matrices (quantum states) $\rho$ and $\rho'$,
	\emph{shadow kernel} \cite{huangPredictingManyProperties2020} is 
	\begin{equation}
		k_{\shadow}(S_T(\dm),S_T'(\dm')) := 
		\exp( \frac{\tau}{T^2}
			\sum_{t,t'=1}^{T} \exp( \frac{\gamma}{n} 
			\sum_{i=1}^n \Tr(\sigma_i^{(t)}\sigma_i^{(t')}) ) 
			)
	\end{equation}	
	where $S_T(\dm)$ is the classical shadow representation of $\dm$.
	The computation time for the inner product is $\bigO(nT^2)$,
	linear in the system size $n$ and quadratic in $T$,
	the number of copies of each quantum state which are measured to construct the classical shadow.
\end{definition}
% \begin{figure}[!ht]
% 	\centering
% 	\includegraphics[scale=.2]{data.png}
% 	% \includegraphics[width=.35\linewidth]{data.jpg}
% 	\caption{computational model powered by training data}
% \end{figure}

\begin{proposition}[\cite{huangPowerDataQuantum2021}]
	exist quantum advantage in machine learning (not significant, practical)	...
	discrete log, factoring...
\end{proposition}
% \begin{theorem}[informal \cite{huangPowerDataQuantum2021}]
% 	data learning
% 	\begin{itemize}
% 		\item machine learning (strictly) more powerful than BPP
% 		\item exist quantum advantage in machine learning (not significant, practical)
% 	\end{itemize}
% \end{theorem}
\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \Input{\nameref{def:classical_shadow}? (features) with label (training data)}
    \Output{entanglement structure? decision; classify phase}
    \BlankLine
    \For{ $i = 1,2, \ldots, m$} {
        kernel estimation \tcp*{classical kernel}
        SVM \tcp*{SVM}
        % \tcc{comment in a new line}
    {\Return "?"}
    }
    \Return $\vb{w}$ \tcp*{parameters of the separating hyperplane in the feature space}
    \caption{Classical learning (\nameref{def:svm}) + classical shadow}
    \label{alg:classical_learning}
\end{algorithm}


\subsection{Quantum trace (kernel) estimation}
\subsubsection{Entanglement spectroscopy via quantum trace estimation}
% \nameref{prm:trace_estimation}
For $\Tr(\dm_A^m)$, an important application of multivariate trace estimation \cite{quekMultivariateTraceEstimation2022} is to entanglement spectroscopy \cite{johriEntanglementSpectroscopyQuantum2017} - deducing the full set of eigenvalues of $\dm_A$. The smallest eigenvalue of diagnoses whether $\psi_{AB}$ is separable or entangled \cite{horodeckiDirectDetectionQuantum2002}. \textbf{constant depth}
\begin{remark}[\cite{horodeckiDirectDetectionQuantum2002}]
	Direct entanglement detections, can be \textbf{employed as sub-routines in quantum computation}. For example, one may consider performing or not performing a quantum operation on a given quantum system conditioned on some part of quantum data being entangled or not. In fact direct entanglement detections can be viewed as quantum computations solving an inherently quantum decision problem: given as an input n copies of decide whether is entangled. Here the \textbf{input data is quantum} and such a decision problem cannot even be even formulated for classical computers. 
	% Nonetheless the problem is perfectly well deﬁned for quantum computers.

	For the sake of completeness we should also mention here that there are two-particle observables, called entanglement witnesses which can detect quantum entanglement is some special cases (see [20,8]). They have positive mean values on all separable states and negative on some entangled states. Therefore \textbf{any individual entanglement witness leaves many entangled states undetected}. When is unknown we need to check inﬁnitely many witnesses, which eﬀectively reduces this approach to the quantum state estimation. However, let us point out any witness deﬁnes a positive map which can be used in our test.
\end{remark}
\begin{definition}[entanglement spectroscopy]\label{def:entanglement_spectroscopy}
	the concept of the entanglement spectrum which is the energy spectrum of the ``entanglement Hamiltonian" $\hamiltonian_E$ defined through $\dm_A = \exp(−\hamiltonian_E )$. They pointed out that the largest eigenvalues of $\dm_A$ [30] contain more universal signatures than the von Neumann \nameref{def:entropy} or $S_2$ alone. (SWAP trick, Quantum phase estimation)
	% Entanglement spectroscopy on a quantum computer
	\cite{johriEntanglementSpectroscopyQuantum2017}:
\end{definition}

\begin{theorem}[\cite{quekMultivariateTraceEstimation2022}]\label{thm:multivariate_trace}
	multivariate \nameref{prm:trace_estimation} can be implemented in constant quantum depth, with only linearly-many controlled two-qubit gates and a linear amount of classical pre-processing	
\end{theorem}
% Multivariate trace estimation in constant quantum depth
% \cite{quekMultivariateTraceEstimation2022}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \Input{(copies of) density matrix (graph state?) $\dm$,...}
    \Output{spectrum of entanglement Hamiltonian}
    \BlankLine
    \For{ $i = 1,2, \ldots, m$} {
        GHZ  \tcp*{prepare GHZ}
        parallel  \tcp*{estimate real and imaginary part respectively}
        % \tcc{comment in a new line}
    {\Return $\lambda$ }
    }
    \Return smallest eigenvalue of $\dm_A$
    \caption{\nameref{def:entanglement_spectroscopy} by ... quantum trace estimation}
    \label{alg:entanglement_spectroscopy}
\end{algorithm}
\begin{remark}[\cite{quekMultivariateTraceEstimation2022}]
	We remark that, an alternative way to estimate $\Tr[ \dm^k ]$ for each $k \in [m]$ is by using the method of classical shadows to obtain `classical snapshots' of $\dm$ that can be linearly combined to obtain a classical random variable whose expectation is $\Tr[ \dm^k ]$ (see Supplementary Material Section 6 of \cite{huangPredictingManyProperties2020}). 
	However, it is \textbf{unclear to us if this method would offer savings in the quantum resources required, as the total number of times the quantum circuit needs to be run in the data acquisition phase should scale with the variance of the corresponding estimator}. 
	We do not know of a concise expression for this variance for arbitrary $m$. Indeed, calculating it for just a single value of $m$ ($m = 2$) required four pages of calculations in \cite{huangPredictingManyProperties2020}.
\end{remark}

\subsubsection{Estimate entanglement witness by quantum machine learning}
The quantum ML algorithm accesses the quantum channel $\mathcal{E}_\dm$ multiple times to obtain multiple copies of the underlying quantum state $\dm$. Each access to $\mathcal{E}_\dm$ allows us to obtain one copy of $\dm$. Then, the quantum ML algorithm performs a sequence of measurements on the copies of $\dm$ to accurately predict $\Tr(P_x \dm ), \forall x \in \qty{ I, X, Y, Z }^n$.
\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \Input{(copies of) density matrix $\dm$, an entanglement witness (observable) $\ew$}
    \Output{$\Tr(P_x \dm ), \forall x \in \qty{ I, X, Y, Z }^n$}
    \BlankLine
    \For{ $i = 1,2, \ldots, m$} {
        $P_x$  \tcp*{estimate entanglement witness by quantum ML}
        % \tcc{comment in a new line}
    % {\Return $\Tr(\ew\dm)$ }
    }
    \Return estimation of $\Tr(\ew\dm)$ 
    % \Return entangled ? GME ? separable with certain partition?
    \caption{\nameref{def:entanglement_witness} by quantum ML}
    \label{alg:entanglement_witness}
\end{algorithm}
\begin{theorem}[\cite{huangInformationtheoreticBoundsQuantum2021}]\label{thm:quantum_ml_estimate_bound}
	For $M$ Pauli opertors, there is a (quantum) procedure estimate every expectation value $\Tr(P_x \dm),\forall i=1,\dots,M$ within error $\epsilon$ under probability at least $1-\delta $ by performing POVM measurements on $\bigO(\log(M/\delta)\epsilon^{-4})$ copies of the unknown quantum state $\dm$.
	($M=4^n$ implies linear copy for full tomography???)
\end{theorem}
\begin{theorem}[\cite{huangInformationtheoreticBoundsQuantum2021}]\label{thm:quantum_vs_classical}
	We rigorously show that, for any quantum process $\mathcal{E}$, observables $\ob$, and distribution $\mathcal{D}$, and for any quantum ML model, one can always design a classical ML model achieving a similar average prediction error such that $N_C$ (number of experiments?) is larger than $N_Q$ by at worst a small polynomial factor.

	In contrast, for achieving accurate prediction on all inputs, we prove that \textbf{exponential quantum advantage is possible}. For example, to predict expectations of all \textbf{Pauli observables} (entanglement witness??) in an $n$-qubit system $\dm$, classical ML models require $2^{\Omega(n)}$ copies of $\dm$ , but we present a quantum ML model using only $\bigO(n)$ copies.
\end{theorem}

\subsubsection{Quantum kernel SVM}
related works:
\begin{itemize}
	\item quantum kernel method: estimate kernels by quantum algorithms (circuits)	\cite{havlicekSupervisedLearningQuantum2019}
	\cite{schuldQuantumMachineLearning2019}: for classical problem (data)

	\item rigorous and robust quantum advantage of quantum kernel method in SVM \cite{liuRigorousRobustQuantum2021}. group structured data \cite{glickCovariantQuantumKernels2021}

	\item power of data in quantum machine learning \cite{huangPowerDataQuantum2021}: input??? projected quantum kernel
\end{itemize}
\begin{definition}[quantum kernel]\label{def:quantum_kernel}
	quantum kernel 
	with quantum feature map $\phi(\vbx): \mathcal{X}\to \op{\phi(\vbx)}$
	\begin{equation}
		k_Q(\rho,\rho') := \abs{\ip{\phi(\vbx)}{\phi(\vbx')}}^2 =\abs{\mel{0}{\U_{\phi(\vbx)}^\dagger \U_{\phi(\vbx')} }{0}}^2 =? \Tr(\rho\rho') \equiv \expval{\dm,\dm'}_{\textup{HS}}
	\end{equation}
	where $\U_{\phi(\vbx)}$ is a quantum circuit or physics process that encoding an input $\vbx$.
	In quantum physics, quantum kernel is also known as transition amplitude (quantum propagator);
\end{definition}
% \begin{definition}[multivariate trace estimation]\label{def:multivariate_trace_estimation}
% 	The task of estimating quantities like 
% 	\begin{equation}
% 		\Tr(\rho_1 \cdots \rho_m)
% 		\tag{multivariate traces}
% 	\end{equation}
% 	given access to copies of the quantum states $\rho_1$  through $\rho_m$.
% \end{definition}
% is a fundamental building block in quantum information science

% power of data - 
\begin{proposition}[\cite{huangPowerDataQuantum2021}]
	If a classical algorithm without training data can compute (label) $y=f(x)=\mel{x}{\U_{\textup{QNN}}^\dagger \ob U_{\textup{QNN}}}{x}$ (with amplitude encoding) efficiently (poly time in ...) for any $\U_{\textup{QNN}}$ and $\ob$, then $\nameref{def:bpp}=\nameref{def:bqp}$ (which is believed unlikely).
\end{proposition}
\begin{proposition}[\cite{huangPowerDataQuantum2021}]
	Training an arbitrarily deep quantum neural network $\U_{\qnn}$ with a trainable observable $\ob$ is equivalent to training a \nameref{def:quantum_kernel} method with kernel $k_{Q}(\vbx,\vbx')=\Tr(\dm(\vbx)\dm'(\vbx'))$
\end{proposition}
\begin{definition}[projected quantum kernel]\label{def:projected_quantum_kernel}
	....
\end{definition}


% \subsubsection{Variational quantum kernel estimation (hybrid)}

\subsection{Variational (hybrid) quantum algorithms}
\subsubsection{Variational entanglement witness (ansatz)}
an ansatz for \nameref{def:entanglement_witness} \cite{zhuMachineLearningDerivedEntanglement2021} (graph state entanglement)
\begin{equation}
	\ew_{ansatz} := \sum_{k_1,k_2,\dots,k_n}  w_{k_1,k_2,\dots,k_n} \bigotimes_i^n \hat{\sigma}^{(k_i)}
	,\quad \hat{\sigma} \in \qty{\sx,\sy,\sz,\identity_{2\times 2}}
\end{equation}
c.f. \nameref{prm:full_tomography} (Stokes parameters) \cref{eq:stokes_tomography}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}
    \Input{(copies of) $\dm$, an entanglement witness (observable) ansatz $\ew_a$}
    \Output{classifier $\vb{w}$}
    \BlankLine
    \For{ $i = 1,2, \ldots, m$} {
        $\dm_{cs}$  \tcp*{classical shadow}
        $\vb{w}\vbx$  \tcp*{optimize SVM}
        % \tcc{comment in a new line}
    % {\Return $\Tr(\ew\dm)$ }
    }
    \Return parameters $\vb{w}$ (SVM hyperplane)
    \caption{ansatz + classical shadow (quantum ML) + classical SVM}
    % \label{alg:entanglement_witness}
\end{algorithm}


\subsubsection{Variational trace estimate (direct)}
Variational Quantum Algorithms for Trace Distance and Fidelity Estimation
\cite{chenVariationalQuantumAlgorithms2022}
\begin{theorem}
	On quantum computers, evaluating the trace distances is probably hard since even judging whether $\dm$ and $\dm'$ have large or small trace distance is known to be QSZK-complete \cite{watrousQuantumComputationalComplexity2008}, where QSZK (quantum statistical zero-knowledge) is a complexity class that includes BQP (bounded-error quantum polynomial time).
\end{theorem}

\subsection{Theoretic upper bounds and lower bounds}
\cite{huangPredictingManyProperties2020}
\cite{huangInformationtheoreticBoundsQuantum2021}
\cite{huangPowerDataQuantum2021}
\cite{aaronsonShadowTomographyQuantum2018}
% \cite{liuRigorousRobustQuantum2021}

\begin{table}[!ht]
\centering
\begin{tabular}{c|c|c|c|c}
	& gate/depth/computation & measurements/samples & query? & input/unknown? \\  
	% necessary?sufficient
	\hline
	% \nameref{prm:full_tomography} & & N/A & $\bigO$, Holevo bound $\Omega$ & \\  
	\nameref{prm:shadow_tomography} & exp circuit? & \cref{thm:shadow_tomography} & N/A & unknown \\  
	% indirect? direct (no prior), promise & & & & \\  
	% promise (low-rank?), partial, decision? & & & & \\  
	\nameref{def:entanglement_witness} & N/A &  \cref{thm:entanglement_witness_gme} (constant?) & convex?\cite{chakrabartiQuantumAlgorithmsLower2020} & known \\  
	\nameref{def:classical_shadow}  & N/A & \cref{thm:classical_shadow_upper,thm:classical_shadow_lower} & N/A & unknown? \\  
	C. ML + C. \nameref{def:entanglement_witness} ansatz  & ?? & Q. advantage \cref{thm:quantum_vs_classical} & N/A & unknown \\  
	QML. \nameref{def:entanglement_witness} ansatz  & ?? & \cref{thm:quantum_ml_estimate_bound} & N/A & unknown \\  
	Q. \nameref{def:entanglement_spectroscopy} &  \cref{thm:multivariate_trace} (c-depth?) & & property test \cite{montanaroSurveyQuantumProperty2018} & unknown\\  
	SVM + quantum kernel estimation &  & &  & ??\\  
	\hline
\end{tabular}
\caption{complexity (different measures) of different methods}
\end{table}

\subsubsection{Separations (complexity)}
contrived problem (engineered dataset)? for exponential speedup

\subsubsection{Obstacles (practical)}
% quantum advantages:
% \begin{itemize}
% 	\item no input encoding problem? \cite{tangQuantumPrincipalComponent2021} in most quantum machine learning algorithm.
% 	\item contrived problem (engineered dataset)? for exponential speedup
% 	% \item convex body query? complexity
% \end{itemize}
% obstacles: (i)

\section{Numerical simulation}
\subsection{Classification accuracy}
\subsubsection{Data preparation}
multi-partite entangled state: generate synthetic (engineered) data from (random graph?).
separable state from randomly ...

\subsubsection{Hyperparameters and settings}
We consider a set of different regularization parameters,...

\subsubsection{Results}
performance of different methods: 
\begin{figure}[!ht]
	\centering
	% \includegraphics[width=1\linewidth]{.pdf}
	\caption{comparison of }
\end{figure}
% \begin{itemize}
% 	\item shadow tomography: 
% 	\item entanglement witness (no machine learning); 
% 	\item classical machine learning; 
% 	\item quantum machine learning
% \end{itemize}

\subsection{Robustness to noise}
tradeoff between (white noise) tolerance (robustness) and efficiency (number of measurements).
\begin{equation}
	\dm_{\noise}' = (1-p_{\noise}) \op{G} + p_{\noise} \frac{\identity}{2^n}
\end{equation}
$p_{\noise}$ indicates the robustness of the algorithm (witness).
\begin{remark}[\cite{zhouDetectingMultipartiteEntanglement2019}]
	the largest noise tolerance $p_{\text{limit}}$ just related to the \textbf{chromatic number} (\nameref{def:graph_property}) of the graph.
\end{remark}
\begin{question}
	other noise (depolarization)? e.g., flip error, phase error?, local, random unitary transformation?
\end{question}
\begin{figure}[!ht]
	\centering
	% \includegraphics[width=1\linewidth]{.pdf}
	\caption{robustness }
\end{figure}
find optimal (robustness) entanglement witness by classical machine learning (qunatum circuit?)

% \input{complexity.tex}
% \input{optimization.tex}

\subsection{Experiments}
future: experimental (photonic) implementation with a few qubits (generation, verification) \cite{luEntanglementStructureEntanglement2018}

\section{Conclusion and discussion}
% \begin{itemize}
% 	\item experiment (generation, verification) \cite{luEntanglementStructureEntanglement2018}
% 	\item error correction? not benchmark
% \end{itemize}

\subsection*{Acknowledgements}
% \thanks{The author thanks} 
% The author thanks
% TikZiT, QuTip

%\begin{appendices}
    %\chapter{}
%\end{appendices}

% %%%%%%%%%%%%%%%Reference%%%%%%%%%%%%%%%
% % \newpage
% % \printbibliography
\bibliographystyle{apsrev4-2}
%\bibliographystyle{alpha}
\bibliography{ref}

%\begin{widetext}
\onecolumngrid
\appendix

\section{Machine learning background}
% In this work, we restrict ourself to supervised learning (mainly SVM), where we are given a set of labeled data for training to predict labels of new data.

Notations:
The (classical) training data (for supervised learning) is a set of $m$ data points $\qty{(\vbx^{(i)}, y^{(i)})}^{m}_{i=1}$ 
where each data point is a pair $(\vbx,y)$.
Normally, the input (e.g., an image) $\vbx:= (x_1,x_2,\dots,x_d) \in \realnumber^d$  is a vector where $d$ is the number of \emph{features}
and its \emph{label} $y\in\Sigma$ is a scalar with some discrete set $\Sigma$ of alphabet/categories. 
For simplicity and the purpose of this paper, we assume $\Sigma=\qty{-1,1}$ (binary classification).

\subsection{Support vector machine}\label{sec:svm}
\begin{definition}[SVM]\label{def:svm}
	Given a set of (binary) labeled data,
	support vector machine (SVM) is designed to
	find a hyperplane (a linear function) such that maximize the margin between two partitions...
	\begin{equation}
		\max_{\vb{w}} 
		....
	\end{equation}
\end{definition}

\subsubsection{kernel method}
nonlinear boundary. map to a higher dimensional (feature) space, in which data is linearly separable.
\nameref{def:kernel}
\begin{definition}[kernel]\label{def:kernel}
	In general, the kernel function $\kernel:\mathcal{X}\times \mathcal{X} \to \realnumber$ measures the similarity between two input data points by an inner product
	\begin{equation}
		\kernel (\vbx,\vbx') : = \expval{\phi(\vbx),\phi(\vbx')}
	\end{equation}
	If the input $\vbx\in \realnumber^d$ (conventional machine learning task, e.g., image classification), the feature map $\phi(\vbx): \realnumber^d\to \realnumber^n$ ($d < n$) from a low dimensional space to a higher dimensional space.
	The corresponding kernel (Gram) matrix $\mathbf{K}$ should be a positive, semidefinite (PSD) matrix.
\end{definition}
\begin{example}[kernels]
	Some common kernels: 
	the polynomial kernel $\kernel_{\text{poly}}(\vbx,\vbx') := (1+\vbx\cdot\vbx')^q$ with feature map $\phi(\vbx)$ ...
	The Gaussian kernel
	$\kernel_{\text{gaus}}(\vbx,\vbx') := \exp(-\gamma\norm{\vbx-\vbx'}^2_2)$ 
		% \begin{equation}
		% 	\kernel_{\text{gaus}}(\vbx,\vbx') := \exp(-\norm{\vbx-\vbx'}^2/(2\beta))
		% \end{equation}
	with an infinite dimensional feature map $\phi(\vbx)$.
	An important feature of kernel method is that kernels can be computed efficiently without evaluating feature map (might be infinite dimension) explicitly.
	% \begin{itemize}
	% 	\item \emph{Gaussian kernel}; 
	% 	\begin{equation}
	% 		\kernel_{\text{gaus}}(\vbx,\vbx') := \exp(-\norm{\vbx-\vbx'}^2/(2\beta))
	% 	\end{equation}
	% 	note that infinite dimensional feature map

		% \item \emph{graph kernel} \cite{kriegeSurveyGraphKernels2020}: given a pair of graphs $(\graph,\graph')$
		% \begin{equation}
		% 	\kernel (\graph,\graph')  =
		% \end{equation}
		% quantum graph kernel $\kernel (\graph,\graph')  = \abs{\ip{\graph}{\graph'}}^2$ ??
		% \cite{baiQuantumJensenShannon2015}

		% \item quantum kernel (transition amplitude / quantum propagator);
		% \begin{equation}
		% 	k_Q(\rho,\rho') := \abs{\ip{\phi(x)}{\phi(x')}}^2 =\abs{\mel{0}{\U_{\phi(x)}^\dagger \U_{\phi(x')} }{0}}^2 = \Tr(\rho\rho')
		% \end{equation}
		% with quantum feature map $\phi(x): \mathcal{X}\to \op{\phi(x)}$

		% \item \emph{shadow kernel}:
		% given two density matrices $\rho$ and $\rho'$
		% \begin{equation}
		% 	k_{\shadow}(\rho,\rho') := 
		% \end{equation}

	% 	\item neural tagent kernel \cite{jacotNeuralTangentKernel2020}: proved to be equivalent to deep neural network \cite{gaoEfficientRepresentationQuantum2017}
	% \end{itemize}
\end{example}

similarity measures? advantages? why? (isomorphism?)
\begin{definition}[divergence]\label{def:divergence}
	KL divergence (relative \nameref{def:entropy}): measure the distance (similarity) between two probability distributions:
	\begin{equation}
		\kl (P || Q) := \sum P(x) \log (P(x)/Q(x))
	\end{equation}
	symmetric version: Jensen-Shannon divergence (machine learning)
	\begin{equation}
		\jsd (P || P') := \frac{1}{2} \qty(\kl(P|| M) + \kl(P'||M))
		\equiv H_S(M)-\frac{1}{2} (H_S(P) - H_S(P') ) 
	\end{equation}
	where $M=(P+P')/2$ and Shannon \nameref{def:entropy} $H_S$.
	Analogously, quantum Jensen-Shannon divergence $D_{\qjs}$ of two density matrices can be defined...
	\begin{equation}
		D_{\qjs}(\dm||\dm'):= 
		H_V(\dm_M) - \frac{1}{2} (H_V(\dm) - H_V(\dm') ) 
	\end{equation}
	as a quantum graph kernel ($\dm$ induced by quantum random walk)
\end{definition}
\begin{definition}[geometric difference]\label{def:geometric_difference}
	\begin{equation}
		g(K^1|| k^2) = \sqrt{\norm{\sqrt{K^2} (K^1)^{-1}\sqrt{K^2}}_{\infty}}
	\end{equation}
	where $\norm{\cdot}_{\infty}$ is the spectral \nameref{def:norm}.
\end{definition}

\subsection{Neural network}\label{sec:neural_network}
\subsubsection{neural network and kernel}
\begin{definition}[neural tagent kernel]\label{def:neural_tangent_kernel}
	neural tangent kernel \cite{jacotNeuralTangentKernel2020}: proved to be equivalent to deep neural network \cite{gaoEfficientRepresentationQuantum2017} in the limit ...
	\begin{equation}
		k_{\ntk} \qty(S_T(\dm_l),\tilde{S}_T(\dm_{l'}))
		=
		\expval{
			\phi^{(\ntk)}(S_T(\dm_l)),
			\phi^{(\ntk)}(\tilde{S}_T(\dm_l))
		}
	\end{equation}
\end{definition}

\subsubsection{Stabilizer formalism}\label{sec:stabilizer_formalism}
denote a group by $\group$ and a subgroup $\subgroup$. 
\begin{definition}[Pauli group]
\end{definition}
\begin{definition}[Clifford group]\label{def:clifford}
\end{definition}
\begin{definition}[Stabilizer]\label{def:stabilizer}
	An observable $S_k$ is a stabilizing operator of an $n$-qubit state $\ket{\psi}$ if the state $\ket{\psi}$ is an eigenstate of $S_k$ with eigenvalue 1,
\end{definition}
Many highly entangled $n$-qubit states can be uniquely defined by $n$ stabilizing operators which are locally measurable, i.e., they are products of Pauli matrices.

\subsubsection{quantum neural network}\label{sec:quantum_neural_network}
% \subsection{Unsupervised: PCA}

\section{Hardness assumptions}
\begin{definition}[\NP]\label{def:np}
	\NP, \NP-hard, \NP-complete
\end{definition}
\begin{definition}[\sharpP]\label{def:sharpp}
	\sharpP
\end{definition}
\begin{definition}[QMA]\label{def:qma}
	QMA
\end{definition}
\begin{definition}[\BPP]\label{def:bpp}
	\BPP
\end{definition}
\begin{definition}[\BQP]\label{def:bqp}
	\BQP
\end{definition}

%\end{widetext}

\end{document}